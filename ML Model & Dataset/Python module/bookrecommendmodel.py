# -*- coding: utf-8 -*-
"""BookRecommendModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6i3WBZKz79Ao8TnItefx6ZQgdV_WFDI
"""

import numpy as np
import pandas as pd
from sklearn.neighbors import NearestNeighbors
from scipy.sparse import csr_matrix

books = pd.read_csv('/content/Books.csv.zip')
users = pd.read_csv('/content/Users.csv.zip')
ratings = pd.read_csv('/content/Ratings.csv.zip')

books.head()

users.head()

ratings.head()

ratings_with_name = ratings.merge(books, on='ISBN')
ratings_with_name

# Filter users who have rated more than 50 books
user_ratings_count = ratings_with_name.groupby('User-ID').count()['Book-Rating']
active_users = user_ratings_count[user_ratings_count > 50].index
filtered_ratings = ratings_with_name[ratings_with_name['User-ID'].isin(active_users)]
# Filter books that have been rated at least 10 times
book_ratings_count = filtered_ratings.groupby('Book-Title').count()['Book-Rating']
popular_books = book_ratings_count[book_ratings_count >= 10].index
final_ratings = filtered_ratings[filtered_ratings['Book-Title'].isin(popular_books)]
final_ratings

pivot_table = final_ratings.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating')
pivot_table.fillna(0, inplace=True)
pivot_table

from sklearn.metrics.pairwise import cosine_similarity
similarity_scores = cosine_similarity(pivot_table)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# Assuming final_ratings and pivot_table are already created as in your script

# Prepare data for TensorFlow model
user_book_matrix = pivot_table.values

# Define features (books) and labels (ratings)
X = user_book_matrix
y = user_book_matrix

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Define a simple feedforward neural network
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(X_train.shape[1], activation='sigmoid')  # Output layer
])

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Convert the model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model
with open('book_recommendation_model.tflite', 'wb') as f:
    f.write(tflite_model)

import tensorflow as tf
import numpy as np

# Load the TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_path="book_recommendation_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

def recommend(book_name=None):
    if book_name is None:
        # Return a random set of 4 books
        random_books = random.sample(list(books['Book-Title']), 5)
        for book in random_books:
            book_data = books.loc[books['Book-Title'] == book].iloc[0]
            print("Book Title:", book_data['Book-Title'])
            print("Author:", book_data['Book-Author'])
            print("Year:", book_data['Year-Of-Publication'])
            print("Image URL:", book_data['Image-URL-M'])
            print("-------------------------------")
    else:
        try:
            index = np.where(pivot_table.index == book_name)[0][0]
            input_data = np.array([pivot_table.iloc[index].values], dtype=np.float32)

            # Set input tensor
            interpreter.set_tensor(input_details[0]['index'], input_data)

            # Run inference
            interpreter.invoke()

            # Get output tensor
            output_data = interpreter.get_tensor(output_details[0]['index'])
            similar_items = sorted(list(enumerate(output_data[0])), key=lambda x: x[1], reverse=True)[1:6]

            for i in similar_items:
                book_id = pivot_table.index[i[0]]
                book_data = books.loc[books['Book-Title'] == book_id].iloc[0]
                print("Book Title:", book_data['Book-Title'])
                print("Author:", book_data['Book-Author'])
                print("Year:", book_data['Year-Of-Publication'])
                print("Image URL:", book_data['Image-URL-M'])
                print("-------------------------------")
        except ValueError:
            print("Book not found in pivot table")
        except Exception as e:
            print("Error:", e)

recommend('The Great Gatsby')

from random import random

import pandas as pd


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

books = pd.read_csv('/content/Books.csv')
users = pd.read_csv('//content/Users.csv')
ratings = pd.read_csv('/content/Ratings.csv')

books.head()
users.head()
ratings.head()

ratings_with_name = ratings.merge(books, on='ISBN')
ratings_with_name

# Filter users who have rated more than 50 books
user_ratings_count = ratings_with_name.groupby('User-ID').count()['Book-Rating']
active_users = user_ratings_count[user_ratings_count > 50].index
filtered_ratings = ratings_with_name[ratings_with_name['User-ID'].isin(active_users)]
# Filter books that have been rated at least 10 times
book_ratings_count = filtered_ratings.groupby('Book-Title').count()['Book-Rating']
popular_books = book_ratings_count[book_ratings_count >= 10].index
final_ratings = filtered_ratings[filtered_ratings['Book-Title'].isin(popular_books)]
final_ratings

pivot_table = final_ratings.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating')
pivot_table.fillna(0, inplace=True)
pivot_table

from sklearn.metrics.pairwise import cosine_similarity

similarity_scores = cosine_similarity(pivot_table)

from sklearn.model_selection import train_test_split

# Assuming final_ratings and pivot_table are already created as in your script

# Prepare data for TensorFlow model
user_book_matrix = pivot_table.values

# Define features (books) and labels (ratings)
X = user_book_matrix
y = user_book_matrix

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Define a simple feedforward neural network
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(X_train.shape[1], activation='sigmoid')  # Output layer
])

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Convert the model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model
with open('book_recommendation_model.tflite', 'wb') as f:
    f.write(tflite_model)

import tensorflow as tf
import numpy as np

# Load the TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_path="book_recommendation_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()


def recommend(book_name=None):
    if book_name is None:
        # Return a random set of 4 books
        random_books = random.sample(list(books['Book-Title']), 5)
        for book in random_books:
            book_data = books.loc[books['Book-Title'] == book].iloc[0]
            print("Book Title:", book_data['Book-Title'])
            print("Author:", book_data['Book-Author'])
            print("Year:", book_data['Year-Of-Publication'])
            print("Image URL:", book_data['Image-URL-M'])
            print("-------------------------------")
    else:
        try:
            index = np.where(pivot_table.index == book_name)[0][0]
            input_data = np.array([pivot_table.iloc[index].values], dtype=np.float32)

            # Set input tensor
            interpreter.set_tensor(input_details[0]['index'], input_data)

            # Run inference
            interpreter.invoke()

            # Get output tensor
            output_data = interpreter.get_tensor(output_details[0]['index'])
            similar_items = sorted(list(enumerate(output_data[0])), key=lambda x: x[1], reverse=True)[1:6]

            for i in similar_items:
                book_id = pivot_table.index[i[0]]
                book_data = books.loc[books['Book-Title'] == book_id].iloc[0]
                print("Book Title:", book_data['Book-Title'])
                print("Author:", book_data['Book-Author'])
                print("Year:", book_data['Year-Of-Publication'])
                print("Image URL:", book_data['Image-URL-M'])
                print("-------------------------------")
        except ValueError:
            print("Book not found in pivot table")
        except Exception as e:
            print("Error:", e)

from flask import Flask, request, jsonify
import pandas as pd
import tensorflow as tf
import numpy as np

app = Flask(__name__)

# Load the TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_path="book_recommendation_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()



def recommend(book_name=None):
    if book_name is None:
        # Return a random set of 4 books
        random_books = random.sample(list(books['Book-Title']), 5)
        recommendations = []
        for book in random_books:
            book_data = books.loc[books['Book-Title'] == book].iloc[0]
            recommendations.append({
                'title': book_data['Book-Title'],
                'author': book_data['Book-Author'],
                'year': book_data['Year-Of-Publication'],
                'image_url': book_data['Image-URL-M']
            })
        return jsonify(recommendations)
    else:
        try:
            index = np.where(pivot_table.index == book_name)[0][0]
            input_data = np.array([pivot_table.iloc[index].values], dtype=np.float32)

            # Set input tensor
            interpreter.set_tensor(input_details[0]['index'], input_data)

            # Run inference
            interpreter.invoke()

            # Get output tensor
            output_data = interpreter.get_tensor(output_details[0]['index'])
            similar_items = sorted(list(enumerate(output_data[0])), key=lambda x: x[1], reverse=True)[1:6]

            recommendations = []
            for i in similar_items:
                book_id = pivot_table.index[i[0]]
                book_data = books.loc[books['Book-Title'] == book_id].iloc[0]
                recommendations.append({
                    'title': book_data['Book-Title'],
                    'author': book_data['Book-Author'],
                    'year': book_data['Year-Of-Publication'],
                    'image_url': book_data['Image-URL-M']
                })
            return jsonify(recommendations)
        except ValueError:
            return jsonify({'error': 'Book not found in pivot table'}), 404
        except Exception as e:
            return jsonify({'error': str(e)}), 500

@app.route('/recommend', methods=['GET'])
def get_recommendations():
    book_name = request.args.get('book_name')
    return recommend(book_name)

if __name__ == "__main__":
    app.run(debug=True)